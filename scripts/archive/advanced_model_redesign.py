#!/usr/bin/env python3
"""
ê³ ê¸‰ ëª¨ë¸ ì¬ì„¤ê³„ ë° ê²€ì¦
1. ì„±ê³µ ëª¨ë¸ (15ë¶„, 1ì‹œê°„) ì¶”ê°€ ê²€ì¦
2. 30ë¶„ ëª¨ë¸ ì‹ ê·œ ê°œë°œ
3. ì‹¤íŒ¨ ëª¨ë¸ (4ì‹œê°„, 1ì¼) ëŒ€ì•ˆ ì ‘ê·¼ë²•
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import ccxt
import joblib
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.feature_selection import SelectKBest, f_classif
from loguru import logger
import warnings
warnings.filterwarnings('ignore')

class AdvancedModelSystem:
    def __init__(self):
        self.exchange = ccxt.binance()
        self.models = {}
        self.scalers = {}

    def enhanced_features(self, df, timeframe):
        """í–¥ìƒëœ íŠ¹ì§• ìƒì„±"""
        features = pd.DataFrame(index=df.index)

        # ê¸°ë³¸ ê°€ê²© íŠ¹ì§•
        for period in [1, 2, 3, 5, 7, 10, 15, 20]:
            if len(df) > period:
                features[f'return_{period}'] = df['close'].pct_change(period)
                features[f'volume_change_{period}'] = df['volume'].pct_change(period)

        # RSI ë‹¤ì¤‘ ê¸°ê°„
        for period in [7, 14, 21, 28]:
            delta = df['close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(period).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(period).mean()
            rs = gain / loss
            features[f'rsi_{period}'] = 100 - (100 / (1 + rs))

        # MACD ë³€í˜•
        for fast, slow in [(12, 26), (5, 35), (10, 20)]:
            exp1 = df['close'].ewm(span=fast).mean()
            exp2 = df['close'].ewm(span=slow).mean()
            features[f'macd_{fast}_{slow}'] = exp1 - exp2

        # ë³¼ë¦°ì € ë°´ë“œ ë‹¤ì¤‘
        for period in [10, 20, 30]:
            sma = df['close'].rolling(period).mean()
            std = df['close'].rolling(period).std()
            features[f'bb_width_{period}'] = (2 * std) / sma
            features[f'bb_position_{period}'] = (df['close'] - sma) / (2 * std)

        # ë³¼ë¥¨ í”„ë¡œíŒŒì¼
        features['volume_sma_ratio'] = df['volume'] / df['volume'].rolling(20).mean()
        features['volume_std'] = df['volume'].rolling(20).std() / df['volume'].rolling(20).mean()

        # ë³€ë™ì„± ì§€í‘œ
        features['true_range'] = pd.concat([
            df['high'] - df['low'],
            abs(df['high'] - df['close'].shift()),
            abs(df['low'] - df['close'].shift())
        ], axis=1).max(axis=1)
        features['atr'] = features['true_range'].rolling(14).mean() / df['close']

        # íŒ¨í„´ ì¸ì‹
        features['doji'] = (abs(df['close'] - df['open']) / (df['high'] - df['low'])).rolling(3).mean()
        features['pin_bar'] = ((df['high'] - df['close']) / (df['high'] - df['low'])).rolling(3).mean()

        # íƒ€ì„í”„ë ˆì„ë³„ íŠ¹ìˆ˜ íŠ¹ì§•
        if timeframe in ['30m', '1h']:
            # ì¤‘ê¸° íŠ¸ë Œë“œ
            for period in [50, 100]:
                if len(df) > period:
                    features[f'ma_{period}_slope'] = df['close'].rolling(period).mean().pct_change(5)

        elif timeframe in ['4h', '1d']:
            # ì¥ê¸° íŠ¸ë Œë“œ (ë‹¤ë¥¸ ì ‘ê·¼)
            if len(df) > 200:
                features['long_trend'] = df['close'] / df['close'].rolling(200).mean()
                features['trend_strength'] = abs(features['long_trend'] - 1)

        return features

    def verify_successful_models(self):
        """ì„±ê³µí•œ ëª¨ë¸ (15ë¶„, 1ì‹œê°„) ì¶”ê°€ ê²€ì¦"""
        logger.info("="*70)
        logger.info("ğŸ” ì„±ê³µ ëª¨ë¸ ì¶”ê°€ ê²€ì¦")
        logger.info("="*70)

        results = {}

        for timeframe in ['15m', '1h']:
            logger.info(f"\n{timeframe} ëª¨ë¸ ì‹¬í™” ê²€ì¦...")

            # ëª¨ë¸ ë¡œë“œ
            try:
                model_path = f'models/practical_{timeframe}_model.pkl'
                scaler_path = f'models/practical_{timeframe}_scaler.pkl'

                model_dict = joblib.load(model_path)
                scaler = joblib.load(scaler_path)

                if 'model' in model_dict:
                    model = model_dict['model']
                else:
                    model = model_dict

                logger.info(f"âœ… {timeframe} ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
            except:
                logger.warning(f"âš ï¸ {timeframe} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
                continue

            # ë‹¤ì–‘í•œ ê¸°ê°„ìœ¼ë¡œ ê²€ì¦
            test_periods = {
                '3ì¼': 288 if timeframe == '15m' else 72,
                '7ì¼': 672 if timeframe == '15m' else 168,
                '14ì¼': 1344 if timeframe == '15m' else 336
            }

            period_results = {}

            for period_name, limit in test_periods.items():
                ohlcv = self.exchange.fetch_ohlcv('BTC/USDT', timeframe, limit=limit)
                df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])

                # íŠ¹ì§• ìƒì„±
                features = self.prepare_basic_features(df)
                labels = self.create_labels(df)

                X = features.dropna()
                y = labels[X.index][:-1]
                X = X[:-1]

                # ì˜ˆì¸¡ ë° í‰ê°€
                correct = 0
                high_conf_correct = 0
                high_conf_total = 0

                for i in range(len(X) // 2, len(X)):
                    X_test = X.iloc[i:i+1]
                    y_true = y.iloc[i]

                    X_scaled = scaler.transform(X_test)

                    if hasattr(model, 'predict_proba'):
                        y_pred = model.predict(X_scaled)[0]
                        proba = model.predict_proba(X_scaled)[0]
                        confidence = max(proba) * 100

                        if confidence >= 70:
                            high_conf_total += 1
                            if y_pred == y_true:
                                high_conf_correct += 1
                    else:
                        y_pred = model.predict(X_scaled)[0]
                        confidence = 60  # ê¸°ë³¸ê°’

                    if y_pred == y_true:
                        correct += 1

                accuracy = (correct / (len(X) - len(X) // 2)) * 100
                high_conf_acc = (high_conf_correct / high_conf_total * 100) if high_conf_total > 0 else 0

                period_results[period_name] = {
                    'accuracy': accuracy,
                    'high_conf_accuracy': high_conf_acc,
                    'high_conf_count': high_conf_total
                }

                logger.info(f"  {period_name}: {accuracy:.1f}% (ê³ ì‹ ë¢°ë„: {high_conf_acc:.1f}%)")

            results[timeframe] = period_results

        return results

    def develop_30m_model(self):
        """30ë¶„ ëª¨ë¸ ì‹ ê·œ ê°œë°œ"""
        logger.info("\n" + "="*70)
        logger.info("ğŸš€ 30ë¶„ ëª¨ë¸ ì‹ ê·œ ê°œë°œ")
        logger.info("="*70)

        # ë°ì´í„° ìˆ˜ì§‘
        logger.info("ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        ohlcv = self.exchange.fetch_ohlcv('BTC/USDT', '30m', limit=1000)
        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])

        # í–¥ìƒëœ íŠ¹ì§• ìƒì„±
        logger.info("í–¥ìƒëœ íŠ¹ì§• ìƒì„± ì¤‘...")
        features = self.enhanced_features(df, '30m')
        labels = self.create_labels(df, threshold=0.0025)  # 30ë¶„ìš© ì„ê³„ê°’

        # ë°ì´í„° ì •ë¦¬
        X = features.dropna()
        y = labels[X.index][:-1]
        X = X[:-1]

        logger.info(f"ë°ì´í„° í¬ê¸°: {X.shape}")
        logger.info(f"í´ë˜ìŠ¤ ë¶„í¬: {y.value_counts().to_dict()}")

        # íŠ¹ì§• ì„ íƒ (ê°€ì¥ ì¤‘ìš”í•œ 30ê°œ)
        selector = SelectKBest(f_classif, k=min(30, X.shape[1]))
        X_selected = selector.fit_transform(X, y)
        selected_features = X.columns[selector.get_support()]
        logger.info(f"ì„ íƒëœ íŠ¹ì§• ìˆ˜: {len(selected_features)}")

        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X_selected, y, test_size=0.2, shuffle=False
        )

        # ìŠ¤ì¼€ì¼ë§
        scaler = RobustScaler()  # ì´ìƒì¹˜ì— ê°•í•œ ìŠ¤ì¼€ì¼ëŸ¬
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # ë‹¤ì–‘í•œ ëª¨ë¸ í…ŒìŠ¤íŠ¸
        models = {
            'RandomForest': RandomForestClassifier(
                n_estimators=200, max_depth=10, min_samples_split=10, random_state=42
            ),
            'GradientBoosting': GradientBoostingClassifier(
                n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42
            ),
            'AdaBoost': AdaBoostClassifier(
                n_estimators=100, learning_rate=1.0, random_state=42
            )
        }

        best_score = 0
        best_model = None
        best_name = None

        for name, model in models.items():
            model.fit(X_train_scaled, y_train)
            y_pred = model.predict(X_test_scaled)
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred, average='weighted')
            recall = recall_score(y_test, y_pred, average='weighted')
            f1 = f1_score(y_test, y_pred, average='weighted')

            logger.info(f"\n{name}:")
            logger.info(f"  ì •í™•ë„: {accuracy:.1%}")
            logger.info(f"  ì •ë°€ë„: {precision:.1%}")
            logger.info(f"  ì¬í˜„ìœ¨: {recall:.1%}")
            logger.info(f"  F1: {f1:.1%}")

            if accuracy > best_score:
                best_score = accuracy
                best_model = model
                best_name = name

        logger.success(f"\nâœ… ìµœê³  ëª¨ë¸: {best_name} (ì •í™•ë„: {best_score:.1%})")

        # ëª¨ë¸ ì €ì¥
        if best_score > 0.55:
            self.models['30m'] = best_model
            self.scalers['30m'] = scaler

            joblib.dump(best_model, 'models/advanced_30m_model.pkl')
            joblib.dump(scaler, 'models/advanced_30m_scaler.pkl')
            joblib.dump(selected_features, 'models/advanced_30m_features.pkl')

            logger.success("âœ… 30ë¶„ ëª¨ë¸ ì €ì¥ ì™„ë£Œ")

        return best_score

    def redesign_long_term_models(self):
        """ì¥ê¸° ëª¨ë¸ ëŒ€ì•ˆ ì ‘ê·¼ë²• - íŠ¸ë Œë“œ ë¶„ë¥˜ë¡œ ë³€ê²½"""
        logger.info("\n" + "="*70)
        logger.info("ğŸ”„ ì¥ê¸° ëª¨ë¸ ëŒ€ì•ˆ ì ‘ê·¼ë²•")
        logger.info("="*70)

        results = {}

        for timeframe in ['4h', '1d']:
            logger.info(f"\n{timeframe} ëŒ€ì•ˆ ëª¨ë¸ ê°œë°œ...")

            # ë°ì´í„° ìˆ˜ì§‘
            limit = 1000 if timeframe == '4h' else 365
            ohlcv = self.exchange.fetch_ohlcv('BTC/USDT', timeframe, limit=limit)
            df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])

            # íŠ¸ë Œë“œ ë ˆì´ë¸” ìƒì„± (ë‹¨ìˆœ ìƒìŠ¹/í•˜ë½ ëŒ€ì‹  íŠ¸ë Œë“œ ê°•ë„)
            labels = self.create_trend_labels(df, timeframe)

            # íŠ¹ì§• ìƒì„± - íŠ¸ë Œë“œ ì¤‘ì‹¬
            features = self.create_trend_features(df, timeframe)

            # ë°ì´í„° ì •ë¦¬
            X = features.dropna()
            y = labels[X.index][:-1]
            X = X[:-1]

            logger.info(f"ë°ì´í„° í¬ê¸°: {X.shape}")
            logger.info(f"íŠ¸ë Œë“œ ë¶„í¬: {y.value_counts().to_dict()}")

            # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, shuffle=False
            )

            # ìŠ¤ì¼€ì¼ë§
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)

            # ê°„ë‹¨í•œ íŠ¸ë Œë“œ ë¶„ë¥˜ê¸°
            model = RandomForestClassifier(
                n_estimators=100,
                max_depth=5,  # ì–•ì€ íŠ¸ë¦¬ë¡œ ê³¼ì í•© ë°©ì§€
                min_samples_split=20,
                random_state=42
            )

            model.fit(X_train_scaled, y_train)
            y_pred = model.predict(X_test_scaled)
            accuracy = accuracy_score(y_test, y_pred)

            logger.info(f"{timeframe} íŠ¸ë Œë“œ ë¶„ë¥˜ ì •í™•ë„: {accuracy:.1%}")

            if accuracy > 0.5:  # 50% ì´ìƒì´ë©´ ì €ì¥
                joblib.dump(model, f'models/trend_{timeframe}_model.pkl')
                joblib.dump(scaler, f'models/trend_{timeframe}_scaler.pkl')
                logger.success(f"âœ… {timeframe} íŠ¸ë Œë“œ ëª¨ë¸ ì €ì¥")

            results[timeframe] = accuracy

        return results

    def create_trend_labels(self, df, timeframe):
        """íŠ¸ë Œë“œ ê°•ë„ ë ˆì´ë¸” (ìƒìŠ¹/íš¡ë³´/í•˜ë½)"""
        if timeframe == '4h':
            lookback = 10  # 40ì‹œê°„
            threshold = 0.02  # 2%
        else:  # 1d
            lookback = 7  # 7ì¼
            threshold = 0.03  # 3%

        trend = (df['close'] / df['close'].shift(lookback) - 1)

        labels = pd.Series(1, index=df.index)  # ê¸°ë³¸ íš¡ë³´
        labels[trend > threshold] = 2  # ê°•í•œ ìƒìŠ¹
        labels[trend < -threshold] = 0  # ê°•í•œ í•˜ë½

        return labels

    def create_trend_features(self, df, timeframe):
        """íŠ¸ë Œë“œ ì¤‘ì‹¬ íŠ¹ì§•"""
        features = pd.DataFrame(index=df.index)

        # ë‹¤ì–‘í•œ ê¸°ê°„ì˜ ì´ë™í‰ê· 
        for period in [20, 50, 100, 200]:
            if len(df) > period:
                ma = df['close'].rolling(period).mean()
                features[f'ma_{period}_ratio'] = df['close'] / ma
                features[f'ma_{period}_slope'] = ma.pct_change(5)

        # íŠ¸ë Œë“œ ê°•ë„
        features['trend_7d'] = df['close'].pct_change(7 if timeframe == '1d' else 42)
        features['trend_14d'] = df['close'].pct_change(14 if timeframe == '1d' else 84)
        features['trend_30d'] = df['close'].pct_change(30 if timeframe == '1d' else 180)

        # ë³€ë™ì„±
        features['volatility_7d'] = df['close'].pct_change().rolling(7).std()
        features['volatility_30d'] = df['close'].pct_change().rolling(30).std()

        # ë³¼ë¥¨ íŠ¸ë Œë“œ
        features['volume_trend'] = df['volume'].rolling(20).mean() / df['volume'].rolling(50).mean()

        # ê³ ì € ë²”ìœ„
        features['high_low_range'] = (df['high'] - df['low']) / df['close']
        features['range_expansion'] = features['high_low_range'].rolling(10).mean()

        return features

    def prepare_basic_features(self, df):
        """ê¸°ë³¸ íŠ¹ì§• (ê²€ì¦ìš©)"""
        features = pd.DataFrame(index=df.index)

        for i in [1, 3, 5, 10]:
            features[f'return_{i}'] = df['close'].pct_change(i)

        for period in [7, 14, 21]:
            delta = df['close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(period).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(period).mean()
            rs = gain / loss
            features[f'rsi_{period}'] = 100 - (100 / (1 + rs))

        exp1 = df['close'].ewm(span=12).mean()
        exp2 = df['close'].ewm(span=26).mean()
        features['macd'] = exp1 - exp2
        features['macd_signal'] = features['macd'].ewm(span=9).mean()
        features['macd_hist'] = features['macd'] - features['macd_signal']

        for period in [10, 20]:
            sma = df['close'].rolling(period).mean()
            std = df['close'].rolling(period).std()
            features[f'bb_position_{period}'] = (df['close'] - sma) / (2 * std)

        features['volume_ratio'] = df['volume'] / df['volume'].rolling(20).mean()
        features['volume_change'] = df['volume'].pct_change()
        features['high_low_ratio'] = (df['high'] - df['low']) / df['close']
        features['close_position'] = (df['close'] - df['low']) / (df['high'] - df['low'])

        return features

    def create_labels(self, df, threshold=0.002):
        """ë ˆì´ë¸” ìƒì„±"""
        future_return = df['close'].shift(-1) / df['close'] - 1
        labels = pd.Series(1, index=df.index)
        labels[future_return > threshold] = 2
        labels[future_return < -threshold] = 0
        return labels

def main():
    system = AdvancedModelSystem()

    logger.info("="*70)
    logger.info("ğŸš€ ê³ ê¸‰ ëª¨ë¸ ì¬ì„¤ê³„ ë° ê²€ì¦")
    logger.info("="*70)

    # 1. ì„±ê³µ ëª¨ë¸ ì¶”ê°€ ê²€ì¦
    verification_results = system.verify_successful_models()

    # 2. 30ë¶„ ëª¨ë¸ ê°œë°œ
    accuracy_30m = system.develop_30m_model()

    # 3. ì¥ê¸° ëª¨ë¸ ëŒ€ì•ˆ ì ‘ê·¼
    long_term_results = system.redesign_long_term_models()

    # ìµœì¢… ë³´ê³ 
    logger.info("\n" + "="*70)
    logger.info("ğŸ“Š ìµœì¢… ê²°ê³¼")
    logger.info("="*70)

    logger.info("\nâœ… ê²€ì¦ëœ ëª¨ë¸:")
    for timeframe, periods in verification_results.items():
        logger.info(f"\n{timeframe}:")
        for period, result in periods.items():
            logger.info(f"  {period}: {result['accuracy']:.1f}%")

    logger.info(f"\nğŸ†• 30ë¶„ ëª¨ë¸: {accuracy_30m:.1%}")

    logger.info("\nğŸ”„ ëŒ€ì•ˆ ì ‘ê·¼ (íŠ¸ë Œë“œ ë¶„ë¥˜):")
    for timeframe, acc in long_term_results.items():
        logger.info(f"  {timeframe}: {acc:.1%}")

    # TodoWrite ì—…ë°ì´íŠ¸
    from datetime import datetime
    logger.info(f"\nâœ… ì‘ì—… ì™„ë£Œ: {datetime.now()}")

if __name__ == "__main__":
    main()