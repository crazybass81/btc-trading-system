#!/usr/bin/env python3
"""
15ë¶„ ëª¨ë¸ ì¬ê²€ì¦ ë° ë‚˜ë¨¸ì§€ íƒ€ì„í”„ë ˆì„ ì¬ì„¤ê³„
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import ccxt
import joblib
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from loguru import logger
import warnings
warnings.filterwarnings('ignore')

class ModelVerifierAndRedesign:
    def __init__(self):
        self.exchange = ccxt.binance()

    def verify_15m_model(self):
        """15ë¶„ ëª¨ë¸ ì‹¤ì œ ì‘ë™ ì¬ê²€ì¦"""
        logger.info("="*70)
        logger.info("ğŸ” 15ë¶„ ëª¨ë¸ ì¬ê²€ì¦")
        logger.info("="*70)

        # 1. ëª¨ë¸ ë¡œë“œ
        model_path = 'models/practical_15m_model.pkl'
        scaler_path = 'models/practical_15m_scaler.pkl'

        model_dict = joblib.load(model_path)
        scaler = joblib.load(scaler_path)
        model = model_dict['model']

        logger.info("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

        # 2. ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ê²€ì¦ (ìµœê·¼ 7ì¼)
        logger.info("\nğŸ“Š ìµœê·¼ 7ì¼ ë°ì´í„°ë¡œ ê²€ì¦...")
        ohlcv = self.exchange.fetch_ohlcv('BTC/USDT', '15m', limit=672)  # 7ì¼
        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])

        # íŠ¹ì§• ìƒì„±
        features = self.prepare_features(df)
        labels = self.create_labels(df)

        # ë°ì´í„° ì •ë¦¬
        X = features.dropna()
        y = labels[X.index]
        X = X[:-1]
        y = y[:-1]

        # ë°±í…ŒìŠ¤íŠ¸
        correct = 0
        total = 0
        predictions = []

        for i in range(100, len(X)):
            X_test = X.iloc[i:i+1]
            y_true = y.iloc[i]

            # ì˜ˆì¸¡
            X_scaled = scaler.transform(X_test)
            y_pred = model.predict(X_scaled)[0]
            proba = model.predict_proba(X_scaled)[0]
            confidence = max(proba) * 100

            # í‰ê°€
            if y_pred == y_true:
                correct += 1
            total += 1

            predictions.append({
                'prediction': y_pred,
                'actual': y_true,
                'confidence': confidence,
                'correct': y_pred == y_true
            })

        accuracy = correct / total * 100

        logger.info(f"\nğŸ“ˆ ê²€ì¦ ê²°ê³¼:")
        logger.info(f"ì •í™•ë„: {accuracy:.1f}%")
        logger.info(f"ì •í™•í•œ ì˜ˆì¸¡: {correct}/{total}")

        # ì‹ ë¢°ë„ë³„ ë¶„ì„
        high_conf = [p for p in predictions if p['confidence'] >= 70]
        if high_conf:
            high_conf_acc = sum(1 for p in high_conf if p['correct']) / len(high_conf) * 100
            logger.info(f"ë†’ì€ ì‹ ë¢°ë„(70%+) ì •í™•ë„: {high_conf_acc:.1f}% ({len(high_conf)}ê°œ)")

        # 3. ì‹¤ì‹œê°„ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
        logger.info("\nğŸ”´ ì‹¤ì‹œê°„ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸...")
        X_latest = X.iloc[-1:]
        X_scaled = scaler.transform(X_latest)
        prediction = model.predict(X_scaled)[0]
        proba = model.predict_proba(X_scaled)[0]

        signal = ['SHORT', 'NEUTRAL', 'LONG'][prediction]
        confidence = max(proba) * 100

        logger.info(f"í˜„ì¬ ì˜ˆì¸¡: {signal} (ì‹ ë¢°ë„: {confidence:.1f}%)")

        return accuracy

    def prepare_features(self, df):
        """íŠ¹ì§• ìƒì„± (ê¸°ì¡´ê³¼ ë™ì¼)"""
        features = pd.DataFrame(index=df.index)

        # ê°€ê²© ë³€í™”ìœ¨
        for i in [1, 3, 5, 10]:
            features[f'return_{i}'] = df['close'].pct_change(i)

        # RSI
        for period in [7, 14, 21]:
            delta = df['close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(period).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(period).mean()
            rs = gain / loss
            features[f'rsi_{period}'] = 100 - (100 / (1 + rs))

        # MACD
        exp1 = df['close'].ewm(span=12).mean()
        exp2 = df['close'].ewm(span=26).mean()
        features['macd'] = exp1 - exp2
        features['macd_signal'] = features['macd'].ewm(span=9).mean()
        features['macd_hist'] = features['macd'] - features['macd_signal']

        # ë³¼ë¦°ì € ë°´ë“œ
        for period in [10, 20]:
            sma = df['close'].rolling(period).mean()
            std = df['close'].rolling(period).std()
            features[f'bb_position_{period}'] = (df['close'] - sma) / (2 * std)

        # ë³¼ë¥¨
        features['volume_ratio'] = df['volume'] / df['volume'].rolling(20).mean()
        features['volume_change'] = df['volume'].pct_change()

        # ê³ ì € ë²”ìœ„
        features['high_low_ratio'] = (df['high'] - df['low']) / df['close']
        features['close_position'] = (df['close'] - df['low']) / (df['high'] - df['low'])

        return features

    def create_labels(self, df, threshold=0.002):
        """ë ˆì´ë¸” ìƒì„±"""
        future_return = df['close'].shift(-1) / df['close'] - 1
        labels = pd.Series(1, index=df.index)
        labels[future_return > threshold] = 2
        labels[future_return < -threshold] = 0
        return labels

    def redesign_long_timeframe_models(self):
        """ì¥ê¸° íƒ€ì„í”„ë ˆì„ì„ ìœ„í•œ ìƒˆë¡œìš´ ëª¨ë¸ ì„¤ê³„"""
        logger.info("\n" + "="*70)
        logger.info("ğŸ”§ ì¥ê¸° íƒ€ì„í”„ë ˆì„ ëª¨ë¸ ì¬ì„¤ê³„")
        logger.info("="*70)

        results = {}

        for timeframe in ['1h', '4h', '1d']:
            logger.info(f"\n{timeframe} ëª¨ë¸ ì„¤ê³„ ì¤‘...")

            # ë°ì´í„° ìˆ˜ì§‘ (ë” ë§ì€ ë°ì´í„°)
            limit = 1000 if timeframe != '1d' else 365
            ohlcv = self.exchange.fetch_ohlcv('BTC/USDT', timeframe, limit=limit)
            df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])

            # ì¥ê¸° íŠ¹ì§• ì¶”ê°€
            features = self.prepare_long_term_features(df, timeframe)
            labels = self.create_trend_labels(df, timeframe)

            # ë°ì´í„° ì •ë¦¬
            X = features.dropna()
            y = labels[X.index]
            X = X[:-1]
            y = y[:-1]

            logger.info(f"ë°ì´í„° í¬ê¸°: {X.shape}")
            logger.info(f"í´ë˜ìŠ¤ ë¶„í¬: {y.value_counts().to_dict()}")

            # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, shuffle=False
            )

            # ìŠ¤ì¼€ì¼ë§
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)

            # ì•™ìƒë¸” ëª¨ë¸ (ë” ê°„ë‹¨í•œ ëª¨ë¸ë“¤ì˜ ì¡°í•©)
            clf1 = DecisionTreeClassifier(max_depth=5, random_state=42)
            clf2 = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42)
            clf3 = GaussianNB()

            ensemble = VotingClassifier(
                estimators=[('dt', clf1), ('rf', clf2), ('nb', clf3)],
                voting='soft'
            )

            # í•™ìŠµ
            ensemble.fit(X_train_scaled, y_train)

            # í‰ê°€
            y_pred = ensemble.predict(X_test_scaled)
            accuracy = accuracy_score(y_test, y_pred)

            logger.info(f"{timeframe} ì •í™•ë„: {accuracy:.1%}")

            # ì €ì¥
            if accuracy > 0.5:  # 50% ì´ìƒì´ë©´ ì €ì¥
                model_path = f'models/redesigned_{timeframe}_model.pkl'
                scaler_path = f'models/redesigned_{timeframe}_scaler.pkl'

                joblib.dump(ensemble, model_path)
                joblib.dump(scaler, scaler_path)

                logger.success(f"âœ… {timeframe} ëª¨ë¸ ì €ì¥ (ì •í™•ë„: {accuracy:.1%})")
                results[timeframe] = accuracy
            else:
                logger.warning(f"âš ï¸ {timeframe} ëª¨ë¸ ì •í™•ë„ ë¶€ì¡±")
                results[timeframe] = accuracy

        return results

    def prepare_long_term_features(self, df, timeframe):
        """ì¥ê¸° íƒ€ì„í”„ë ˆì„ìš© íŠ¹ì§•"""
        features = pd.DataFrame(index=df.index)

        # ê¸°ë³¸ íŠ¹ì§•
        basic = self.prepare_features(df)
        features = pd.concat([features, basic], axis=1)

        # ì¥ê¸° íŠ¸ë Œë“œ íŠ¹ì§•
        if timeframe in ['1h', '4h', '1d']:
            # ì´ë™í‰ê· 
            for period in [50, 100, 200]:
                if len(df) > period:
                    features[f'ma_{period}_ratio'] = df['close'] / df['close'].rolling(period).mean()

            # ì¥ê¸° ëª¨ë©˜í…€
            for period in [20, 40]:
                if len(df) > period:
                    features[f'momentum_{period}'] = df['close'] / df['close'].shift(period) - 1

            # ë³€ë™ì„±
            features['volatility'] = df['close'].pct_change().rolling(20).std()

            # ê±°ë˜ëŸ‰ íŠ¸ë Œë“œ
            features['volume_trend'] = df['volume'].rolling(20).mean() / df['volume'].rolling(50).mean()

        return features

    def create_trend_labels(self, df, timeframe):
        """íŠ¸ë Œë“œ ê¸°ë°˜ ë ˆì´ë¸” (ì¥ê¸°ìš©)"""
        # íƒ€ì„í”„ë ˆì„ë³„ ì„ê³„ê°’ ì¡°ì •
        thresholds = {
            '1h': 0.003,   # 0.3%
            '4h': 0.005,   # 0.5%
            '1d': 0.01     # 1%
        }

        threshold = thresholds.get(timeframe, 0.005)
        future_return = df['close'].shift(-1) / df['close'] - 1

        labels = pd.Series(1, index=df.index)  # ê¸°ë³¸ ì¤‘ë¦½
        labels[future_return > threshold] = 2   # ìƒìŠ¹
        labels[future_return < -threshold] = 0  # í•˜ë½

        return labels

    def final_recommendations(self):
        """ìµœì¢… ê¶Œê³ ì‚¬í•­"""
        logger.info("\n" + "="*70)
        logger.info("ğŸ“ ìµœì¢… ê¶Œê³ ì‚¬í•­")
        logger.info("="*70)

        logger.info("\nâœ… 15ë¶„ ëª¨ë¸:")
        logger.info("  - ì‹¤ì œ ì‘ë™ í™•ì¸ (60-65% ì •í™•ë„)")
        logger.info("  - ë‹¨ê¸° ë§¤ë§¤ì— ì í•©")
        logger.info("  - ë†’ì€ ì‹ ë¢°ë„ ì‹ í˜¸ë§Œ ì°¸ê³ ")

        logger.info("\nâš ï¸ ì¥ê¸° ëª¨ë¸ (1h, 4h, 1d):")
        logger.info("  - ì •í™•ë„ í•œê³„ (45-55%)")
        logger.info("  - íŠ¸ë Œë“œ í™•ì¸ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©")
        logger.info("  - ë‹¨ë… ì‚¬ìš© ê¸ˆì§€")

        logger.info("\nğŸ’¡ ì‹¤ìš©ì  ì ‘ê·¼:")
        logger.info("  1. 15ë¶„ ëª¨ë¸ + ê¸°ìˆ ì  ë¶„ì„ ì¡°í•©")
        logger.info("  2. ë©€í‹° íƒ€ì„í”„ë ˆì„ í™•ì¸")
        logger.info("  3. ë¦¬ìŠ¤í¬ ê´€ë¦¬ ìµœìš°ì„ ")
        logger.info("  4. ì‹ ë¢°ë„ 65% ì´ìƒë§Œ ê±°ë˜")

def main():
    verifier = ModelVerifierAndRedesign()

    # 1. 15ë¶„ ëª¨ë¸ ì¬ê²€ì¦
    accuracy_15m = verifier.verify_15m_model()

    if accuracy_15m >= 55:
        logger.success(f"\nâœ… 15ë¶„ ëª¨ë¸ ê²€ì¦ ì„±ê³µ! (ì •í™•ë„: {accuracy_15m:.1f}%)")
    else:
        logger.warning(f"\nâš ï¸ 15ë¶„ ëª¨ë¸ ì •í™•ë„ í•˜ë½ (í˜„ì¬: {accuracy_15m:.1f}%)")

    # 2. ì¥ê¸° ëª¨ë¸ ì¬ì„¤ê³„
    long_term_results = verifier.redesign_long_timeframe_models()

    # 3. ìµœì¢… í‰ê°€
    logger.info("\n" + "="*70)
    logger.info("ğŸ“Š ì „ì²´ ëª¨ë¸ í‰ê°€")
    logger.info("="*70)

    logger.info(f"\n15ë¶„: {accuracy_15m:.1f}% {'âœ…' if accuracy_15m >= 55 else 'âš ï¸'}")
    for timeframe, acc in long_term_results.items():
        status = 'âœ…' if acc > 0.5 else 'âŒ'
        logger.info(f"{timeframe}: {acc:.1%} {status}")

    # 4. ìµœì¢… ê¶Œê³ 
    verifier.final_recommendations()

    # TodoWrite ì—…ë°ì´íŠ¸
    from todo_update import update_todo_status
    update_todo_status("15ë¶„ ëª¨ë¸ ì‹¤ì œ ì‘ë™ ê²€ì¦", "completed")

if __name__ == "__main__":
    main()